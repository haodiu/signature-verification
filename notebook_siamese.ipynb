{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6896743,"sourceType":"datasetVersion","datasetId":3961745},{"sourceId":6898366,"sourceType":"datasetVersion","datasetId":3962616},{"sourceId":6898392,"sourceType":"datasetVersion","datasetId":3962632},{"sourceId":6908812,"sourceType":"datasetVersion","datasetId":3967799},{"sourceId":6908996,"sourceType":"datasetVersion","datasetId":3967901},{"sourceId":6920944,"sourceType":"datasetVersion","datasetId":3974060},{"sourceId":6968288,"sourceType":"datasetVersion","datasetId":4003603},{"sourceId":6968320,"sourceType":"datasetVersion","datasetId":4003627},{"sourceId":6968618,"sourceType":"datasetVersion","datasetId":4003818},{"sourceId":6979984,"sourceType":"datasetVersion","datasetId":4011081},{"sourceId":6982571,"sourceType":"datasetVersion","datasetId":4012924},{"sourceId":6982600,"sourceType":"datasetVersion","datasetId":4012946},{"sourceId":6982623,"sourceType":"datasetVersion","datasetId":4012962},{"sourceId":6982629,"sourceType":"datasetVersion","datasetId":4012966},{"sourceId":6982646,"sourceType":"datasetVersion","datasetId":4012979},{"sourceId":6990853,"sourceType":"datasetVersion","datasetId":4018117},{"sourceId":7011297,"sourceType":"datasetVersion","datasetId":4031138},{"sourceId":7011342,"sourceType":"datasetVersion","datasetId":4031172},{"sourceId":7011621,"sourceType":"datasetVersion","datasetId":4031360},{"sourceId":7011628,"sourceType":"datasetVersion","datasetId":4031365},{"sourceId":7011851,"sourceType":"datasetVersion","datasetId":4031514},{"sourceId":7015048,"sourceType":"datasetVersion","datasetId":4033318},{"sourceId":7015344,"sourceType":"datasetVersion","datasetId":4033497},{"sourceId":7015572,"sourceType":"datasetVersion","datasetId":4033634}],"dockerImageVersionId":30588,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import ImageOps\n\nfrom PIL import Image\nfrom torch.utils.data import DataLoader","metadata":{"execution":{"iopub.status.busy":"2023-11-21T14:31:22.378344Z","iopub.execute_input":"2023-11-21T14:31:22.378751Z","iopub.status.idle":"2023-11-21T14:31:24.497378Z","shell.execute_reply.started":"2023-11-21T14:31:22.378712Z","shell.execute_reply":"2023-11-21T14:31:24.496438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SiameseDataset():\n    def __init__(self, training_csv=None, training_dir=None, transform=None):\n        # Load image file paths and labels from the CSV file\n        self.train_df = pd.read_csv(training_csv, header=None)\n        self.train_df.columns = [\"image1\", \"image2\", \"label\"]\n        self.train_dir = training_dir\n        self.transform = transform\n\n    def __getitem__(self, index):\n        image1_path = os.path.join(self.train_dir, self.train_df.iat[index, 0])\n        image2_path = os.path.join(self.train_dir, self.train_df.iat[index, 1])\n\n        img1 = Image.open(image1_path)\n        img2 = Image.open(image2_path)\n\n        img1 = img1.convert(\"L\")\n        img2 = img2.convert(\"L\")\n\n        if self.transform is not None:\n            img1 = self.transform(img1)\n            img2 = self.transform(img2)\n\n        label = int(self.train_df.iat[index, 2])\n\n        return (\n            img1,\n            img2,\n            torch.from_numpy(\n                np.array([int(self.train_df.iat[index, 2])], dtype=np.float32)\n            ),\n        )\n\n    def __len__(self):\n        return len(self.train_df)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T14:31:24.498455Z","iopub.execute_input":"2023-11-21T14:31:24.498829Z","iopub.status.idle":"2023-11-21T14:31:24.505320Z","shell.execute_reply.started":"2023-11-21T14:31:24.498805Z","shell.execute_reply":"2023-11-21T14:31:24.504434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class SiameseDataset():\n#     def __init__(self, training_csv=None, training_dir=None, transform=None):\n#         # Load image file paths and labels from the CSV file\n#         self.train_df = pd.read_csv(training_csv, header=None)\n#         self.train_df.columns = [\"image1\", \"image2\", \"label\"]\n#         self.train_dir = training_dir\n#         self.transform = transform\n\n#     def adjust_pixel_values(self, image):\n#         # Điều chỉnh giá trị của ảnh tại đây\n#         image_array = np.array(image)\n#         threshold_value = 245\n#         adjusted_array = np.where(image_array < threshold_value, image_array, 255)\n#         return Image.fromarray(adjusted_array.astype('uint8'))\n\n#     def __getitem__(self, index):\n#         image1_path = os.path.join(self.train_dir, self.train_df.iat[index, 0])\n#         image2_path = os.path.join(self.train_dir, self.train_df.iat[index, 1])\n\n#         img1 = Image.open(image1_path)\n#         img2 = Image.open(image2_path)\n\n#         img1 = img1.convert(\"L\")\n#         img2 = img2.convert(\"L\")\n\n#         img1 = self.adjust_pixel_values(img1)\n#         img2 = self.adjust_pixel_values(img2)\n\n#         if self.transform is not None:\n#             img1 = self.transform(img1)\n#             img2 = self.transform(img2)\n\n#         label = int(self.train_df.iat[index, 2])\n\n#         return (\n#             img1,\n#             img2,\n#             torch.from_numpy(\n#                 np.array([int(self.train_df.iat[index, 2])], dtype=np.float32)\n#             ),\n#         )\n\n#     def __len__(self):\n#         return len(self.train_df)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T14:31:24.508163Z","iopub.execute_input":"2023-11-21T14:31:24.508505Z","iopub.status.idle":"2023-11-21T14:31:24.520494Z","shell.execute_reply.started":"2023-11-21T14:31:24.508474Z","shell.execute_reply":"2023-11-21T14:31:24.519619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SiameseNetwork(nn.Module):\n    def __init__(self):\n        super(SiameseNetwork, self).__init__()\n        self.cnn = nn.Sequential(\n            nn.Conv2d(1, 48, kernel_size=11, stride=1),\n            nn.BatchNorm2d(48),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(3, stride=2),\n\n            nn.Conv2d(48, 128, kernel_size=5, stride=1, padding=2),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(3, stride=2),\n            nn.Dropout(p=0.3),\n\n            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n\n            nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(3, stride=2),\n            nn.Dropout(p=0.3),\n        )\n        self.fc = nn.Sequential(\n            nn.Linear(25*17*128, 1024),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=0.5),\n\n            nn.Linear(1024, 128),\n            nn.ReLU(inplace=True),\n        )\n\n    def forward_once(self, x):\n        output = self.cnn(x)\n        output = output.view(output.size()[0], -1)\n        output = self.fc(output)\n        return output\n\n    def forward(self, input1, input2):\n        output1 = self.forward_once(input1)\n        output2 = self.forward_once(input2)\n        return output1, output2","metadata":{"execution":{"iopub.status.busy":"2023-11-21T14:31:24.521521Z","iopub.execute_input":"2023-11-21T14:31:24.521759Z","iopub.status.idle":"2023-11-21T14:31:24.535583Z","shell.execute_reply.started":"2023-11-21T14:31:24.521738Z","shell.execute_reply":"2023-11-21T14:31:24.534747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class SiameseNetwork(nn.Module):\n#     def __init__(self):\n#         super(SiameseNetwork, self).__init__()\n#         # Define CNN layers\n#         self.cnn = nn.Sequential(\n#             nn.Conv2d(1, 96, kernel_size=11, stride=1),\n#             nn.ReLU(inplace=True),\n#             nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2),\n#             nn.MaxPool2d(3, stride=2),\n\n#             nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n#             nn.ReLU(inplace=True),\n#             nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2),\n#             nn.MaxPool2d(3, stride=2),\n#             nn.Dropout(p=0.3),\n\n#             nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n#             nn.ReLU(inplace=True),\n\n#             nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n#             nn.ReLU(inplace=True),\n#             nn.MaxPool2d(3, stride=2),\n#             nn.Dropout(p=0.3),\n#         )\n#         # Fully connected layers\n#         self.fc = nn.Sequential(\n#             nn.Linear(25*17*256, 1024),\n#             nn.ReLU(inplace=True),\n#             nn.Dropout(p=0.5),\n\n#             nn.Linear(1024, 128),\n#             nn.ReLU(inplace=True),\n#         )\n\n#     def forward_once(self, x):\n#         output = self.cnn(x)\n#         output = output.view(output.size()[0], -1)\n#         output = self.fc(output)\n#         return output\n\n#     def forward(self, input1, input2):\n#         output1 = self.forward_once(input1)\n#         output2 = self.forward_once(input2)\n#         return output1, output2","metadata":{"execution":{"iopub.status.busy":"2023-11-21T14:31:24.536711Z","iopub.execute_input":"2023-11-21T14:31:24.537568Z","iopub.status.idle":"2023-11-21T14:31:24.549589Z","shell.execute_reply.started":"2023-11-21T14:31:24.537535Z","shell.execute_reply":"2023-11-21T14:31:24.548692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ContrastiveLoss(nn.Module):\n    def __init__(self, margin=2.0):\n        super(ContrastiveLoss, self).__init__()\n        self.margin = margin\n\n    def forward(self, output1, output2, label):\n        euclidean_distance = output1 - output2\n\n        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) + (\n            label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n\n        return loss_contrastive","metadata":{"execution":{"iopub.status.busy":"2023-11-21T14:31:24.550519Z","iopub.execute_input":"2023-11-21T14:31:24.550783Z","iopub.status.idle":"2023-11-21T14:31:24.563884Z","shell.execute_reply.started":"2023-11-21T14:31:24.550760Z","shell.execute_reply":"2023-11-21T14:31:24.563000Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tranform images\nimage_transforms = transforms.Compose(\n    [transforms.Resize((155, 220)), transforms.ToTensor()])","metadata":{"execution":{"iopub.status.busy":"2023-11-21T14:31:24.564963Z","iopub.execute_input":"2023-11-21T14:31:24.565221Z","iopub.status.idle":"2023-11-21T14:31:24.574317Z","shell.execute_reply.started":"2023-11-21T14:31:24.565198Z","shell.execute_reply":"2023-11-21T14:31:24.573451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show plot\ndef show_plot(train_losses, val_losses, epochs):\n    plt.figure(figsize=(10, 6))\n    plt.plot(range(1, epochs+1), train_losses, label='Train Loss')\n    plt.plot(range(1, epochs+1), val_losses, label='Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.title('Train and Validation Loss')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-21T14:31:24.575152Z","iopub.execute_input":"2023-11-21T14:31:24.575395Z","iopub.status.idle":"2023-11-21T14:31:24.587728Z","shell.execute_reply.started":"2023-11-21T14:31:24.575373Z","shell.execute_reply":"2023-11-21T14:31:24.586892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_dir = '/kaggle/input/update-sign-12/chuky/chuky'\ntrain_csv = '/kaggle/input/update-sign-12/train2.csv'\nvalidate_csv = '/kaggle/input/update-sign-12/validate2.csv'\n\nepochs = 90\n\nmodel = SiameseNetwork().cuda()\n\ntrain_dataset = SiameseDataset(train_csv, train_dir, transform=image_transforms)\ntrain_dataloader = DataLoader(train_dataset, shuffle=True, num_workers=4,\n                      pin_memory=True, batch_size=16)\n\nvalidate_dataset = SiameseDataset(validate_csv, train_dir, transform=image_transforms)\nvalidate_dataloader = DataLoader(validate_dataset, shuffle=True, num_workers=4,\n                      pin_memory=True, batch_size=16)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0005)\ncriterion = ContrastiveLoss()\n\ndef train(train_dataloader):\n    loss=[]\n    model.train()\n    for i, data in enumerate(train_dataloader,0):\n      img0, img1 , label = data\n      img0, img1 , label = img0.cuda(), img1.cuda() , label.cuda()\n      optimizer.zero_grad()\n      output1,output2 = model(img0,img1)\n      loss_contrastive = criterion(output1,output2,label)\n      loss_contrastive.backward()\n      optimizer.step()\n      loss.append(loss_contrastive.item())\n    loss = np.array(loss)\n    return loss.mean() / len(train_dataloader)\n\ndef validate(validate_dataloader):\n    loss=[]\n    model.eval()\n    for i, data in enumerate(validate_dataloader,0):\n      img0, img1 , label = data\n      img0, img1 , label = img0.cuda(), img1.cuda() , label.cuda()\n      output1,output2 = model(img0,img1)\n      loss_contrastive = criterion(output1,output2,label)\n      loss.append(loss_contrastive.item())\n    loss = np.array(loss)\n    return loss.mean() / len(validate_dataloader)\n\ntrain_losses = []\nval_losses = []\n\nfor epoch in range(0, epochs):\n  train_loss = train(train_dataloader) \n  val_loss = validate(validate_dataloader)\n  print('Epoch ', epoch+1)\n  print(f\"Training loss {train_loss}\")\n  print(f\"Validate loss {val_loss}\")\n  train_losses.append(train_loss)\n  val_losses.append(val_loss)\n  # Tạo thư mục lưu trữ nếu nó chưa tồn tại\n  save_dir = \"/kaggle/working/checkpoint\"\n  os.makedirs(save_dir, exist_ok=True)\n    \n  file_path = f\"{save_dir}/model_epoch_{epoch+1}.pt\"\n  torch.save(model.state_dict(), file_path)\n\nshow_plot(train_losses, val_losses, epochs)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T14:31:24.590163Z","iopub.execute_input":"2023-11-21T14:31:24.590443Z","iopub.status.idle":"2023-11-21T14:31:24.600075Z","shell.execute_reply.started":"2023-11-21T14:31:24.590397Z","shell.execute_reply":"2023-11-21T14:31:24.599241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_checkpoint = SiameseNetwork().cuda()\ncheckpoint = torch.load('/kaggle/input/checkpoint/model_epoch_19.pt')\nmodel_checkpoint.load_state_dict(checkpoint)\n\ntrain_dir = '/kaggle/input/dataset-dir/train/train'\ntrain_csv = '/kaggle/input/train-val-csv/new_train.csv'\nvalidate_csv = '/kaggle/input/train-val-csv/new_validate.csv'\n\ntrain_dataset = SiameseDataset(training_csv=train_csv, training_dir=train_dir, transform=image_transforms)\nvalidate_dataset = SiameseDataset(training_csv=validate_csv, training_dir=train_dir, transform=image_transforms)\n\ntrain_dataloader = DataLoader(train_dataset, shuffle=True, num_workers=2,pin_memory=True, batch_size=22)\nvalidate_dataloader = DataLoader(validate_dataset, shuffle=True, num_workers=2,pin_memory=True, batch_size=22)\n\nprint(len(train_dataloader), len(validate_dataloader))\n\ndef compute_distance_optimal(predictions, labels):\n    distance_max = np.max(predictions)\n    distance_min = np.min(predictions)\n#     print('distance_max = ', distance_max)\n#     print('distance_min = ', distance_min)\n\n    num_same = np.sum(labels == 0)\n    num_different = np.sum(labels == 1)\n#     print('num_same = ', num_same)\n#     print('num_different = ', num_different)\n\n    step = 0.0005\n    max_accuracy = 0\n\n    distance_optimal = 0\n    for distance in np.arange(distance_min, distance_max + step, step):\n        same_signature_mask = predictions.ravel() <= distance\n        different_signature_mask = predictions.ravel() > distance\n\n        true_positive_rate = float(np.sum(labels[same_signature_mask] == 0)) / num_same\n        true_negative_rate = float(np.sum(labels[different_signature_mask] == 1)) / num_different\n\n        accuracy = 0.5 * (true_positive_rate + true_negative_rate)\n\n        if accuracy > max_accuracy:\n            max_accuracy = accuracy\n            distance_optimal = distance\n\n    return max_accuracy, distance_optimal\n\ndef compute_total_distance_optimal():\n    total_accuracy = 0\n    total_distance_optimal = 0\n    num_batch = 0\n    model_checkpoint.eval()\n    for batch_index, data in enumerate(validate_dataloader, 0):\n        img1, img2, label = data\n        output1, output2 = model_checkpoint(img1.cuda(), img2.cuda())\n        eucledian_distance = F.pairwise_distance(output1, output2)\n        batch_max_acc, distance_optimal = compute_distance_optimal(eucledian_distance.cpu().detach().numpy(), label.detach().numpy())\n#         print('Độ chính xác cao nhất của batch {} = {} tại distance_optimal = {} \\n'.format(batch_index+1, batch_max_acc, distance_optimal))\n        total_accuracy += batch_max_acc\n        total_distance_optimal += distance_optimal\n        num_batch += 1\n    average_accuracy = total_accuracy / num_batch\n    average_distance_optimal = total_distance_optimal / num_batch\n    return average_accuracy, average_distance_optimal\n\naverage_accuracy, threshold = compute_total_distance_optimal()\nprint('Trung bình độ chính xác trên tất cả batch = {}, threshold = {}'.format(average_accuracy, threshold))","metadata":{"execution":{"iopub.status.busy":"2023-11-21T15:30:16.527254Z","iopub.execute_input":"2023-11-21T15:30:16.527679Z","iopub.status.idle":"2023-11-21T15:35:53.155055Z","shell.execute_reply.started":"2023-11-21T15:30:16.527642Z","shell.execute_reply":"2023-11-21T15:35:53.153939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = SiameseNetwork().cuda()\ncheckpoint = torch.load('/kaggle/input/checkpoint/model_epoch_19.pt')\nmodel.load_state_dict(checkpoint)\n\ntest_dir = '/kaggle/input/dataset-dir/test/test'\ntest_csv = '/kaggle/input/new-test-csv/test_data.csv'\n\ntrain_dir = '/kaggle/input/dataset-dir/train/train'\ntrain_csv = '/kaggle/input/train-val-csv/new_train.csv'\nvalidate_csv = '/kaggle/input/train-val-csv/new_validate.csv'\n\ntest_dataset = SiameseDataset(training_csv=test_csv, training_dir=test_dir, transform=image_transforms)\ntest_dataloader = DataLoader(test_dataset, shuffle=True, batch_size=16)\n\ntrain_dataset = SiameseDataset(training_csv=train_csv, training_dir=train_dir, transform=image_transforms)\ntrain_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=16)\n\nvalidate_dataset = SiameseDataset(training_csv=validate_csv, training_dir=train_dir, transform=image_transforms)\nvalidate_dataloader = DataLoader(validate_dataset, shuffle=True, batch_size=16)\n\nthreshold = 5.5899291904739785\n\ndef test_with_threshold(dataloader, len_dataset):\n    TP = 0\n    TN = 0\n    model.eval()\n    count_true_predict = 0  # Số lượng dự đoán đúng\n    from_wrong_to_right = 0  # Số lượng dự đoán sai thành đúng\n    from_right_to_wrong = 0  # Số lượng dự đoán đúng thành sai\n    for batch_index, data in enumerate(dataloader, 0):\n        img1, img2, label = data\n        output1, output2 = model(img1.cuda(), img2.cuda())\n        euclidean_distance = F.pairwise_distance(output1, output2)\n\n        predictions = (euclidean_distance <= threshold).float()\n        predictions = 1 - predictions\n        predicted_labels = np.array(predictions.cpu(), dtype=np.float32)\n        true_labels = np.array(label).flatten()\n\n        count_true_predict += np.sum(predicted_labels == true_labels)\n\n        for i in range(len(true_labels)):\n            if predicted_labels[i] != true_labels[i]:\n                if predicted_labels[i] == 1:\n                    from_right_to_wrong += 1\n            if predicted_labels[i] == true_labels[i] and predicted_labels[i] == 0:\n                    TP += 1\n\n    from_wrong_to_right = len_dataset - count_true_predict - from_right_to_wrong\n    FP = from_wrong_to_right\n    FN = from_right_to_wrong\n    \n    precision = TP / (TP + FP)\n    recall = TP / (TP + FN)\n    F1_score = 2 * (precision * recall) / (precision + recall)\n\n    print(f'Tổng số lượng dự đoán: {len_dataset}')\n    print(f'Số lượng dự đoán đúng: {count_true_predict}')\n    print(f'Số lượng dự đoán sai: {len_dataset - count_true_predict}')\n    print(f'Số lượng dự đoán sai thành đúng: {from_wrong_to_right}')\n    print(f'Số lượng dự đoán đúng thành sai: {from_right_to_wrong}')\n    print(f'Độ chính xác: {(count_true_predict / len_dataset) * 100}')\n    print(f'F1-score: {F1_score}')\n\ntest_with_threshold(test_dataloader, len(test_dataset))","metadata":{"execution":{"iopub.status.busy":"2023-11-21T15:46:14.262511Z","iopub.execute_input":"2023-11-21T15:46:14.262911Z","iopub.status.idle":"2023-11-21T15:47:24.288958Z","shell.execute_reply.started":"2023-11-21T15:46:14.262881Z","shell.execute_reply":"2023-11-21T15:47:24.288016Z"},"trusted":true},"execution_count":null,"outputs":[]}]}